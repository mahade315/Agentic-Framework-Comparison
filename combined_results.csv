Approach/Framework,Dataset/Benchmark,pass@1,pass@2,pass@3,pass@4,pass@5,pass@6,pass@7,pass@8,pass@9,pass@10,Time (sec),Input Tokens,Output Tokens,Total Tokens,Estimated Cost ($),Timestamp,Model,Tasks,Samples per Task
CrewAI Agent,HumanEval,0.3475609756097561,0.4146341463414634,0.4451219512195122,0.47560975609756095,0.4878048780487805,0.5,0.5060975609756098,0.5060975609756098,0.524390243902439,0.5365853658536586,2256.184829711914,143600,76435,220035,1.8645,2025-10-19 12:01:29,gpt-4o,164,10
OpenAI Direct,HumanEval,1.0,1.0,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,2.3811793327331543,278,28,306,0.0018,2025-10-19 12:04:12,gpt-4o,1,2
OpenAI Direct,HumanEval,1.0,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,N/A,1.3047940731048584,139,14,153,0.0009,2025-10-19 12:04:33,gpt-4o,1,1
